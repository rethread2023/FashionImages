{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflowjs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9780\\201337653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflowjs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfjss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflowjs'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflowjs as tfjss\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "\n",
    "# Path ke folder dataset\n",
    "dataset_folder = 'images/'\n",
    "\n",
    "# Path ke file styles.csv\n",
    "styles_file = 'styles.csv'\n",
    "\n",
    "# Membaca data dari file styles.csv\n",
    "data = pd.read_csv(styles_file)\n",
    "\n",
    "# Membaca gambar dan label dari folder dataset\n",
    "images = []\n",
    "\n",
    "\n",
    "# Memuat label ke dalam variabel\n",
    "label_csv = data['articleType']\n",
    "\n",
    "\n",
    "# Mengonversi label FashionImage menjadi tipe data string\n",
    "label_csv = label_csv.astype(str)\n",
    "\n",
    "# Menggabungkan gambar dari folder 'images' dengan dataset MNIST\n",
    "image_folder = 'images/'\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Mengubah gambar menjadi skala abu-abu (grayscale)\n",
    "    image = cv2.resize(image, (28, 28))  # Menyesuaikan dimensi gambar menjadi 28x28\n",
    "    image = np.expand_dims(image, axis=-1)  # Menambahkan dimensi kanal (1) pada gambar\n",
    "    images.append(image)\n",
    "\n",
    "# Konversi data gambar menjadi array numpy\n",
    "images_data = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah gambar  (44441, 28, 28, 1)\n",
      "jumlah label  (44441,)\n"
     ]
    }
   ],
   "source": [
    "# Mengubah label menjadi angka menggunakan LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(label_csv)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "#mengetahui jumlah data\n",
    "print('jumlah gambar ', images_data.shape)\n",
    "print('jumlah label ', label_csv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi dataset menjadi data training, data test, dan data validasi\n",
    "x_train, x_test, y_train, y_test = train_test_split(images_data, labels, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalisasi pixel gambar menjadi rentang [0, 1]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_val = x_val.astype('float32') / 255\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.95:\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 168s 296ms/step - loss: 2.4926 - accuracy: 0.3703 - val_loss: 1.5338 - val_accuracy: 0.5786\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 137s 246ms/step - loss: 1.4512 - accuracy: 0.6026 - val_loss: 1.1624 - val_accuracy: 0.6664\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 190s 341ms/step - loss: 1.1818 - accuracy: 0.6675 - val_loss: 1.0031 - val_accuracy: 0.7044\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 176s 316ms/step - loss: 1.0413 - accuracy: 0.7016 - val_loss: 0.9116 - val_accuracy: 0.7282\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 150s 269ms/step - loss: 0.9533 - accuracy: 0.7217 - val_loss: 0.8918 - val_accuracy: 0.7339\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 174s 312ms/step - loss: 0.8797 - accuracy: 0.7382 - val_loss: 0.8353 - val_accuracy: 0.7467\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 185s 333ms/step - loss: 0.8257 - accuracy: 0.7516 - val_loss: 0.8190 - val_accuracy: 0.7501\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 184s 332ms/step - loss: 0.7816 - accuracy: 0.7627 - val_loss: 0.7926 - val_accuracy: 0.7595\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 182s 328ms/step - loss: 0.7356 - accuracy: 0.7743 - val_loss: 0.7688 - val_accuracy: 0.7669\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 201s 362ms/step - loss: 0.6997 - accuracy: 0.7793 - val_loss: 0.7449 - val_accuracy: 0.7771\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 216s 388ms/step - loss: 0.6650 - accuracy: 0.7891 - val_loss: 0.7386 - val_accuracy: 0.7699\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 180s 324ms/step - loss: 0.6349 - accuracy: 0.7969 - val_loss: 0.7759 - val_accuracy: 0.7624\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 177s 318ms/step - loss: 0.6047 - accuracy: 0.8035 - val_loss: 0.7476 - val_accuracy: 0.7816\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 165s 297ms/step - loss: 0.5834 - accuracy: 0.8129 - val_loss: 0.7643 - val_accuracy: 0.7766\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 150s 270ms/step - loss: 0.5560 - accuracy: 0.8164 - val_loss: 0.7331 - val_accuracy: 0.7775\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 126s 227ms/step - loss: 0.5259 - accuracy: 0.8271 - val_loss: 0.7409 - val_accuracy: 0.7872\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 118s 212ms/step - loss: 0.5111 - accuracy: 0.8300 - val_loss: 0.7293 - val_accuracy: 0.7838\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 148s 266ms/step - loss: 0.4833 - accuracy: 0.8379 - val_loss: 0.7563 - val_accuracy: 0.7849\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 162s 291ms/step - loss: 0.4709 - accuracy: 0.8424 - val_loss: 0.8090 - val_accuracy: 0.7755\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 236s 425ms/step - loss: 0.4494 - accuracy: 0.8480 - val_loss: 0.7695 - val_accuracy: 0.7919\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 229s 413ms/step - loss: 0.4268 - accuracy: 0.8547 - val_loss: 0.8088 - val_accuracy: 0.7939\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 182s 327ms/step - loss: 0.4159 - accuracy: 0.8583 - val_loss: 0.7462 - val_accuracy: 0.7960\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 147s 264ms/step - loss: 0.3954 - accuracy: 0.8632 - val_loss: 0.8039 - val_accuracy: 0.7881\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 128s 231ms/step - loss: 0.3863 - accuracy: 0.8671 - val_loss: 0.8008 - val_accuracy: 0.7879\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 121s 217ms/step - loss: 0.3707 - accuracy: 0.8700 - val_loss: 0.8412 - val_accuracy: 0.7930\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 117s 210ms/step - loss: 0.3517 - accuracy: 0.8763 - val_loss: 0.8698 - val_accuracy: 0.7894\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 115s 207ms/step - loss: 0.3504 - accuracy: 0.8781 - val_loss: 0.8741 - val_accuracy: 0.7883\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 116s 209ms/step - loss: 0.3338 - accuracy: 0.8821 - val_loss: 0.9021 - val_accuracy: 0.7946\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 782s 1s/step - loss: 0.3149 - accuracy: 0.8894 - val_loss: 0.8881 - val_accuracy: 0.7964\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 116s 209ms/step - loss: 0.3099 - accuracy: 0.8899 - val_loss: 0.9471 - val_accuracy: 0.7876\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 115s 206ms/step - loss: 0.3046 - accuracy: 0.8909 - val_loss: 0.9573 - val_accuracy: 0.7921\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 117s 210ms/step - loss: 0.2988 - accuracy: 0.8933 - val_loss: 0.9617 - val_accuracy: 0.7939\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 115s 207ms/step - loss: 0.2844 - accuracy: 0.8996 - val_loss: 0.9737 - val_accuracy: 0.7912\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 114s 204ms/step - loss: 0.2736 - accuracy: 0.9027 - val_loss: 0.9651 - val_accuracy: 0.7897\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 150s 270ms/step - loss: 0.2666 - accuracy: 0.9050 - val_loss: 1.0028 - val_accuracy: 0.8013\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 143s 258ms/step - loss: 0.2599 - accuracy: 0.9070 - val_loss: 1.0291 - val_accuracy: 0.7915\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 141s 253ms/step - loss: 0.2514 - accuracy: 0.9092 - val_loss: 1.0925 - val_accuracy: 0.7944\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 141s 254ms/step - loss: 0.2469 - accuracy: 0.9120 - val_loss: 1.0798 - val_accuracy: 0.7928\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 136s 245ms/step - loss: 0.2452 - accuracy: 0.9115 - val_loss: 1.0343 - val_accuracy: 0.7930\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 141s 253ms/step - loss: 0.2343 - accuracy: 0.9154 - val_loss: 1.1291 - val_accuracy: 0.7906\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 139s 250ms/step - loss: 0.2266 - accuracy: 0.9189 - val_loss: 1.0894 - val_accuracy: 0.7948\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 142s 256ms/step - loss: 0.2246 - accuracy: 0.9189 - val_loss: 1.1953 - val_accuracy: 0.7885\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 169s 304ms/step - loss: 0.2199 - accuracy: 0.9219 - val_loss: 1.1567 - val_accuracy: 0.7888\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 156s 280ms/step - loss: 0.2098 - accuracy: 0.9239 - val_loss: 1.1987 - val_accuracy: 0.7980\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 170s 305ms/step - loss: 0.2139 - accuracy: 0.9240 - val_loss: 1.2428 - val_accuracy: 0.7892\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 153s 275ms/step - loss: 0.2028 - accuracy: 0.9277 - val_loss: 1.2493 - val_accuracy: 0.7980\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 130s 234ms/step - loss: 0.1952 - accuracy: 0.9303 - val_loss: 1.3738 - val_accuracy: 0.7885\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 139s 249ms/step - loss: 0.2011 - accuracy: 0.9278 - val_loss: 1.2560 - val_accuracy: 0.7926\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 138s 248ms/step - loss: 0.1951 - accuracy: 0.9301 - val_loss: 1.2357 - val_accuracy: 0.7951\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 131s 236ms/step - loss: 0.1880 - accuracy: 0.9330 - val_loss: 1.2704 - val_accuracy: 0.7960\n",
      "139/139 [==============================] - 5s 35ms/step - loss: 1.1670 - accuracy: 0.8058\n",
      "Test Loss: 1.1669939756393433\n",
      "Test Accuracy: 0.8058055639266968\n"
     ]
    }
   ],
   "source": [
    "# Membangun arsitektur model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "]) \n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Pelatihan model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_val, y_val), callbacks=[callbacks])\n",
    "\n",
    "# Evaluasi model pada data test\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Predicted Label: Jackets\n"
     ]
    }
   ],
   "source": [
    "# Path ke gambar yang akan diprediksi\n",
    "image_path = 'gambarTest/1.jpg'\n",
    "\n",
    "# Membaca gambar\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "image = cv2.resize(image, (28, 28))\n",
    "image = np.expand_dims(image, axis=-1)  \n",
    "image = image.astype('float32') / 255\n",
    "\n",
    "# Melakukan prediksi\n",
    "predictions = model.predict(np.array([image]))\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Mengonversi kelas prediksi menjadi label\n",
    "predicted_label = label_encoder.classes_[predicted_class]\n",
    "\n",
    "# Menampilkan hasil prediksi\n",
    "print('Predicted Label:', predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path untuk menyimpan model TensorFlow.js\n",
    "tfjs_model_path = 'tfjs_model' #Konversi ke JSON\n",
    "\n",
    "# Konversi model ke format TensorFlow.js\n",
    "tfjss.converters.save_keras_model(model, tfjs_model_path)\n",
    "\n",
    "# Simpan model\n",
    "model.save('image_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE SAMPE SINI AJA :'D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
